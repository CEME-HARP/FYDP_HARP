import os
import logging
import datetime
import whisper
from langchain_ollama import ChatOllama, OllamaEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_text_splitters import CharacterTextSplitter
from langchain.chains import create_retrieval_chain
from langchain_community.document_loaders import PyPDFLoader
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.prompts import PromptTemplate
import pyaudio
import wave

# Configure logging
logging.basicConfig(level=logging.INFO)

# Global variables
llm = None
embeddings = None
pages = None
retrieval_chain = None

# Initialize Whisper model
whisper_model = whisper.load_model("small")

def ask_ollama(user_query, context):
    if context:
        prompt = f"{user_query}\n\nAccording to the schedule: \n{context} "
    else:
        prompt = user_query

    try:
        response = llm.predict(prompt)
        return response
    except Exception as e:
        logging.error(f"An error occurred: {e}")
        return None

def initialize_components():
    global llm, embeddings, pages, retrieval_chain

    llm = ChatOllama(model="gemma2:2b")
    embeddings = OllamaEmbeddings(model="gemma2:2b")

    loader = PyPDFLoader("/home/mak/Documents/local_llm_code/newdata.pdf")
    text_splitter = CharacterTextSplitter(
        separator=".",
        chunk_size=2000,
        chunk_overlap=1000,
        length_function=len,
        is_separator_regex=False,
    )
    pages = loader.load_and_split(text_splitter)

    vectordb = Chroma.from_documents(pages, embeddings)
    retriever = vectordb.as_retriever(search_kwargs={"k": min(5, len(pages))})

    prompt_template = """You are HARP, a Humanoid Assistant Robot. You assist people with their queries in a friendly and natural manner.
    If the answer is not in the provided context, just say "Sorry, I couldn't find any specific data on that. Can you specify which professor or topic you are asking about?"

    context:
    {context}?

    input:
    {input}

    answer:
    """
    prompt = PromptTemplate.from_template(prompt_template)

    combine_docs_chain = create_stuff_documents_chain(llm, prompt)
    retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)

def get_current_datetime():
    now = datetime.datetime.now()
    current_day = now.strftime("%A")
    current_date = now.strftime("%Y-%m-%d")
    current_time = now.strftime("%H:%M")
    return current_day, current_date, current_time

def record_audio(filename, duration=5, rate=16000, chunk=1024):
    p = pyaudio.PyAudio()
    stream = p.open(format=pyaudio.paInt16, channels=1, rate=rate, input=True, frames_per_buffer=chunk)

    frames = []
    print("Listening...")
    for _ in range(0, int(rate / chunk * duration)):
        data = stream.read(chunk)
        frames.append(data)

    stream.stop_stream()
    stream.close()
    p.terminate()

    with wave.open(filename, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))
        wf.setframerate(rate)
        wf.writeframes(b''.join(frames))

def main():
    global pages, retrieval_chain

    query_counter = 0
    initialize_components()

    while True:
        try:
            audio_file = "temp_audio.wav"
            record_audio(audio_file)

            result = whisper_model.transcribe(audio_file)
            query = result["text"].strip()
            print(f"You said: {query}")

            if any(keyword.lower() in query.lower() for keyword in ["quit", "stop", "Allah Hafiz", "bye"]):
                print("Enjoyed talking to you. If you need any help in the future, you can ask me.")
                break

            if any(keyword in query.lower() for keyword in ["today", "time", "date", "day"]):
                current_day, current_date, current_time = get_current_datetime()
                datetime_info = f"Today is {current_day}, {current_date}. The current time is {current_time}."
                query = f"{query}\n\n{datetime_info}"

            response = retrieval_chain.invoke({"input": query})
            result = response["answer"]

            if result and "I couldn't find any specific data on that." not in result:
                print('Answers Generated By RAG')
                print(result)
            else:
                print('Answers Generated By Ollama')
                pdf_content = "\n".join(page.page_content for page in pages)
                ollama_response = ask_ollama(query, pdf_content)
                print(ollama_response)

            query_counter += 1
            if query_counter >= 3:
                initialize_components()
                query_counter = 0

        except Exception as e:
            print(f"An error occurred: {e}")

if __name__ == "__main__":
    main()
